
```python
import numpy as np

NETWORK_SHAPE = [2, 3, 4, 2]


def activation_ReLu(inputs):
    return np.maximum(0, inputs)


# 因为这个矩阵在后面，所以几行几列就是几个输入，几个输出
def create_weights(n_inputs, n_neurons):
    return np.random.randn(n_inputs, n_neurons)


def create_biases(n_neurons):
    return np.random.randn(n_neurons)


class Layer():
    def __init__(self, n_inputs, n_neurons):
        self.weights = np.random.randn(n_inputs, n_neurons)
        self.biases = np.random.randn(n_neurons)

    def layer_forward(self, inputs):
        sum1 = np.dot(inputs, self.weights) + self.biases
        self.output = activation_ReLu(sum1)
        return self.output


class Network():
    def __init__(self, network_shape):
        self.shape = network_shape
        self.n_layers = len(network_shape) - 1
        self.layers = []
        for i in range(len(network_shape) - 1):
            layer = Layer(network_shape[i], network_shape[i + 1])
            self.layers.append(layer)

    def network_forward(self, inputs):
        outputs = [inputs]
        for i in range(self.n_layers):
            layer_output = self.layers[i].layer_forward(outputs[i])
            outputs.append(layer_output)
        return outputs


a11 = 0.9
a12 = -0.4

a21 = -0.8
a22 = 0.5

a31 = -0.5
a32 = 0.8

a41 = 0.7
a42 = -0.3

a51 = -0.9
a52 = 0.4
# 5行2列，2是自拟定的，5行是五个神经元所以5个数据，一个数据有2个像素，行块表示一个数据，一共是一个batch
inputs = np.array([[a11, a12],
                   [a21, a22],
                   [a31, a32],
                   [a41, a42],
                   [a51, a52]])


def main():
    network = Network(NETWORK_SHAPE)  # 建立
    print(network.network_forward(inputs))  # 前馈


main()



```

来增加复杂度，让他运行的更好！